{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "with open(\"../docker/sources.json\", 'r') as input_file:\n",
    "    json_data = json.load(input_file)\n",
    "\n",
    "total_bytes = defaultdict(int)\n",
    "\n",
    "data_size = {\n",
    "    None: 4,\n",
    "    'int8': 1,\n",
    "    'uint8': 2,\n",
    "    'int16': 2,\n",
    "    'uint16': 2,\n",
    "    'int32': 4,\n",
    "    'uint32': 4,\n",
    "    'int64': 8,\n",
    "    'uint64': 8,\n",
    "    'float32': 4,\n",
    "    'float64': 8,\n",
    "    'string': 1,\n",
    "    'bool': 1\n",
    "}\n",
    "\n",
    "for device_name, channel_data in json_data.items():\n",
    "    for channel in channel_data:\n",
    "        total_bytes[device_name] = reduce(lambda x1, x2: x1*x2, channel[\"shape\"], 1) * data_size[channel[\"type\"]]\n",
    "\n",
    "total_bytes = [(x, y) for x, y in total_bytes.items()]\n",
    "total_bytes.sort(key=lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pulse_stats(data):\n",
    "    total = sum([x[1] for x in data])\n",
    "    n_items = len(data)\n",
    "    avg = total/n_items\n",
    "    \n",
    "    return total, n_items, avg\n",
    "\n",
    "total_small, n_small, avg_small = get_pulse_stats([x for x in total_bytes if x[1]<4096])\n",
    "total_large, n_large, avg_large = get_pulse_stats([x for x in total_bytes if 4096<=x[1]<=16384 and x[1]])\n",
    "total_giga, n_giga, avg_giga = get_pulse_stats([x for x in total_bytes if x[1]>16384])\n",
    "\n",
    "total_data = total_small + total_large + total_giga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_time_stats(avg_size):\n",
    "    # avg_size is in bytes\n",
    "    mb_s = avg_size * 100 / 1024 / 1024\n",
    "    # Expecting 100MB partitions\n",
    "    s_per_partition = 100 / mb_s\n",
    "    gb_day = mb_s/1024 * 3600 * 24\n",
    "    \n",
    "    return mb_s, s_per_partition, gb_day\n",
    "\n",
    "mb_s_small, s_per_partition_small, gb_day_small = get_time_stats(avg_small)\n",
    "mb_s_large, s_per_partition_large, gb_day_large = get_time_stats(avg_large)\n",
    "mb_s_giga, s_per_partition_giga, gb_day_giga = get_time_stats(avg_giga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average data volume / pulse / source (b) other:\t 7.9212376933895925\n",
      "Number of sources other:\t 711\n",
      "Daily data volume (Gb) other:\t 0.06373924545094937\n",
      "Seconds per partition other:\t 132375.2727272727\n",
      "% of DAQ other:\t 0.013160005099501975\n",
      "\n",
      "Average data volume / pulse / source (b) LLRF:\t 4936.205128205128\n",
      "Number of sources LLRF:\t 78\n",
      "Daily data volume (Gb) LLRF:\t 39.71980168269231\n",
      "Seconds per partition LLRF:\t 212.4255319148936\n",
      "% of DAQ other:\t 0.8996658031659532\n",
      "\n",
      "Average data volume / pulse / source (b) CAMERAS:\t 2494451.7647058824\n",
      "Number of sources CAMERAS:\t 17\n",
      "Seconds per partition CAMERAS:\t 0.42036330982075987\n",
      "Daily data volume (Gb) CAMERAS:\t 20071.923031526454\n",
      "% of DAQ other:\t 99.08717419173453\n"
     ]
    }
   ],
   "source": [
    "print(\"Average data volume / pulse / source (b) other:\\t\", avg_small)\n",
    "print(\"Number of sources other:\\t\", n_small)\n",
    "print(\"Daily data volume (Gb) other:\\t\", mb_s_small/1024 * 3600 * 24)\n",
    "print(\"Seconds per partition other:\\t\", 100/mb_s_small)\n",
    "print(\"% of DAQ other:\\t\", total_small/total_data * 100)\n",
    "print()\n",
    "\n",
    "print(\"Average data volume / pulse / source (b) LLRF:\\t\", avg_large)\n",
    "print(\"Number of sources LLRF:\\t\", n_large)\n",
    "print(\"Daily data volume (Gb) LLRF:\\t\", mb_s_large/1024 * 3600 * 24)\n",
    "print(\"Seconds per partition LLRF:\\t\", 100/mb_s_large)\n",
    "print(\"% of DAQ other:\\t\", total_large/total_data * 100)\n",
    "print()\n",
    "\n",
    "print(\"Average data volume / pulse / source (b) CAMERAS:\\t\", avg_giga)\n",
    "print(\"Number of sources CAMERAS:\\t\", n_giga)\n",
    "print(\"Seconds per partition CAMERAS:\\t\", 100/mb_s_giga)\n",
    "print(\"Daily data volume (Gb) CAMERAS:\\t\", mb_s_giga/1024 * 3600 * 24)\n",
    "print(\"% of DAQ other:\\t\", total_giga/total_data * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
